{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('../gestos/train', transform=train_transforms)\n",
    "valid_dataset = datasets.ImageFolder('../gestos/valid', transform=valid_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,num_workers=8, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,num_workers=8, batch_size=32, shuffle=False)\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18.04896903038025\n"
     ]
    }
   ],
   "source": [
    "#Congelamos todos los parámetros\n",
    "for param in model.parameters(): \n",
    "    param.requires_grad = False\n",
    "\n",
    "# Recuperamos el número de neuronas de la última capa\n",
    "neurons = model.fc.in_features \n",
    "# La reemplazamos por una nueva capa de salida\n",
    "model.fc = torch.nn.Linear(neurons, 4) \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1):\n",
    "    i=0\n",
    "    for x, y in train_loader:\n",
    "        if i > 10:\n",
    "            break\n",
    "        i = i + 1\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model.forward(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    i=0\n",
    "    for x, y in valid_loader:\n",
    "        if i > 10:\n",
    "            break\n",
    "        i = i + 1\n",
    "        yhat = model.forward(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        epoch_loss += loss.item()\n",
    "    print(epoch, epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,  62, 343,  80],\n",
       "       [ 22,  72, 306, 100],\n",
       "       [ 13,  55, 349,  83],\n",
       "       [ 17,  63, 337,  83]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.03      0.05       500\n",
      "           1       0.29      0.14      0.19       500\n",
      "           2       0.26      0.70      0.38       500\n",
      "           3       0.24      0.17      0.20       500\n",
      "\n",
      "    accuracy                           0.26      2000\n",
      "   macro avg       0.25      0.26      0.21      2000\n",
      "weighted avg       0.25      0.26      0.21      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets, predictions = [], []\n",
    "for mbdata, label in valid_loader:\n",
    "    logits = model.forward(mbdata)\n",
    "    predictions.append(logits.argmax(dim=1).detach().numpy())\n",
    "    targets.append(label.numpy())\n",
    "predictions = np.concatenate(predictions)\n",
    "targets = np.concatenate(targets)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(targets, predictions)\n",
    "display(cm)\n",
    "\n",
    "print(classification_report(targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
