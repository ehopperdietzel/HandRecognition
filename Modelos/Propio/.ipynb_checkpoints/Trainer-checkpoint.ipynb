{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#!unzip './gestos.zip' -d './'\n",
    "#!pip install tensorboard\n",
    "#!pip install pytorch-ignite\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "#os.mkdir('/kaggle/working/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros\n",
    "\n",
    "bachSize = 32\n",
    "max_epochs = 200\n",
    "trainPath = '/kaggle/input/gestos/gestos/train'\n",
    "validPath = '/kaggle/input/gestos/gestos/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders y transformaciones\n",
    "\n",
    "transform = transforms.Compose(\n",
    "[\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(0.25),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transformVal = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(trainPath, transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(validPath, transform=transformVal)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bachSize, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del dataset de entrenamiento\n",
    "\n",
    "# Función para mostrar imágenes\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Obtenemos fotos de 1 batch\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Las mostramos\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(type(self), self).__init__()\n",
    "        self.c1 = nn.Conv2d(3, 32, kernel_size=11, stride=4, padding=2)\n",
    "        self.c2 = nn.Conv2d(32,96, kernel_size=5, padding=2)\n",
    "        self.c3 = nn.Conv2d(96,192, kernel_size=3, padding=1)\n",
    "        self.c4 = nn.Conv2d(192, 128, kernel_size=3, padding=1)\n",
    "        self.c5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.ac = nn.ReLU(inplace=True)\n",
    "        self.mp = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.ap = nn.AdaptiveAvgPool2d((3, 3))\n",
    "        self.f1 = nn.Linear(1152, 512)\n",
    "        self.f2 = nn.Linear(512, 512)\n",
    "        self.f3 = nn.Linear(512, 4)\n",
    "    def forward(self, x):\n",
    "        x = self.mp(self.ac(self.c1(x)))\n",
    "        x = self.mp(self.ac(self.c2(x)))\n",
    "        x = self.ac(self.c3(x))\n",
    "        x = self.ac(self.c4(x))\n",
    "        x = self.mp(self.ac(self.c5(x)))\n",
    "        x = self.ap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        #display(x.shape)\n",
    "        #return\n",
    "        x = self.ac(self.f1(x))\n",
    "        x = self.ac(self.f2(x))\n",
    "        x = self.f3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el número de salidas de la última capa\n",
    "model = HandModel()\n",
    "display(model)\n",
    "model.forward(train_dataset[0][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HandModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Esto es lo que hace el engine de entrenamiento\n",
    "def train_one_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    yhat = model.forward(x)\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Esto es lo que hace el engine de evaluación\n",
    "def evaluate_one_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yhat = model.forward(x)\n",
    "        return yhat, y\n",
    "\n",
    "trainer = Engine(train_one_step)\n",
    "evaluator = Engine(evaluate_one_step)\n",
    "metrics = {'Loss': Loss(criterion), 'Acc': Accuracy()}\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envío a tensorboard y checkpoints\n",
    "with SummaryWriter(log_dir=f'/kaggle/working/') as writer:\n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "    def log_results(engine):\n",
    "        evaluator.run(train_loader) \n",
    "        writer.add_scalar(\"train/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        writer.add_scalar(\"train/accy\", evaluator.state.metrics['Acc'], engine.state.epoch)\n",
    "        evaluator.run(valid_loader) \n",
    "        writer.add_scalar(\"valid/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        writer.add_scalar(\"valid/accy\", evaluator.state.metrics['Acc'], engine.state.epoch)\n",
    "        \n",
    "        # Guardamos el modelo cada época\n",
    "        torch.save(model.state_dict(), '/kaggle/working/models/HandModel-'+str(engine.state.epoch)+\".pt\")\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de archivos\n",
    "\n",
    "#import shutil\n",
    "#import os\n",
    "\n",
    "#os.mkdir('/kaggle/working/models/')\n",
    "#source = '/kaggle/working/'\n",
    "#dest1 = '/kaggle/working/models/'\n",
    "#\n",
    "#files = os.listdir(source)\n",
    "\n",
    "#for f in files:\n",
    "    #shutil.move(source+f, dest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.make_archive('/kaggle/working/Mod3','zip','/kaggle/working/models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
